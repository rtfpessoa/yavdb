---
- id: snykio:maven:org.apache.spark:spark-core_2.10:31462
  title: Cross-site Scripting (XSS)
  description: |+
    [`org.apache.spark:spark-core_2.10`][1] is a fast and general cluster
    computing system for Big Data.

    Affected versions of this package are vulnerable to Cross-site Scripting
    (XSS) attacks.

    In Apache Spark before 2.2.0, it is possible for an attacker to take
    advantage of a user\'s trust in the server to trick them into visiting a
    link that points to a shared Spark cluster and submits data including
    MHTML to the Spark master, or history server. This data, which could
    contain a script, would then be reflected back to the user and could be
    evaluated and executed by MS Windows-based clients. It is not an attack
    on Spark itself, but on the user, who may then execute the script
    inadvertently when viewing elements of the Spark web UIs.



    [1]: https://spark.apache.org
    \nA cross-site scripting attack occurs when the attacker tricks a
    legitimate web-based application or site to accept a request as
    originating from a trusted source.

    This is done by escaping the context of the web application; the web
    application then delivers that data to its users along with other
    trusted dynamic content, without validating it. The browser unknowingly
    executes malicious script on the client side (through client-side
    languages; usually JavaScript or HTML) in order to perform actions that
    are otherwise typically blocked by the browser’s Same Origin Policy.

    ֿInjecting malicious code is the most prevalent manner by which XSS is
    exploited; for this reason, escaping characters in order to prevent this
    manipulation is the top method for securing code against this
    vulnerability.

    Escaping means that the application is coded to mark key characters, and
    particularly key characters included in user input, to prevent those
    characters from being interpreted in a dangerous context. For example,
    in HTML, `<` can be coded as `&lt`; and `>` can be coded as `&gt`; in
    order to be interpreted and displayed as themselves in text, while
    within the code itself, they are used for HTML tags. If malicious
    content is injected into an application that escapes special characters
    and that malicious content uses `<` and `>` as HTML tags, those
    characters are nonetheless not interpreted as HTML tags by the browser
    if they’ve been correctly escaped in the application code and in this
    way the attempted attack is diverted.

    The most prominent use of XSS is to steal cookies (source: OWASP
    HttpOnly) and hijack user sessions, but XSS exploits have been used to
    expose sensitive information, enable access to privileged services and
    functionality and deliver malware.

    ### Types of attacks   {#types-of-attacks}

    There are a few methods by which XSS can be manipulated:

    | Type | Origin | Description |
    |----------
    | **Stored** | Server | The malicious code is inserted in the application (usually as a link) by the attacker. The code is activated every time a user clicks the link. |
    | **Reflected** | Server | The attacker delivers a malicious link externally from the vulnerable web site application to a user. When clicked, malicious code is sent to the vulnerable web site, which reflects the attack back to the user’s browser. |
    | **DOM-based** | Client | The attacker forces the user’s browser to render a malicious page. The data in the page itself delivers the cross-site scripting data. |
    | **Mutated** |  | The attacker injects code that appears safe, but is then rewritten and modified by the browser, while parsing the markup. An example is rebalancing unclosed quotation marks or even adding quotation marks to unquoted parameters. |

    ### Affected environments   {#affected-environments}

    The following environments are susceptible to an XSS attack:

    * Web servers
    * Application servers
    * Web application environments

    ### How to prevent   {#how-to-prevent}

    This section describes the top best practices designed to specifically
    protect your code:

    * Sanitize data input in an HTTP request before reflecting it back,
      ensuring all data is validated, filtered or escaped before echoing
      anything back to the user, such as the values of query parameters
      during searches.
    * Convert special characters such as `?`, `&`, `/`, `<`, `>` and spaces
      to their respective HTML or URL encoded equivalents.
    * Give users the option to disable client-side scripts.
    * Redirect invalid requests.
    * Detect simultaneous logins, including those from two separate IP
      addresses, and invalidate those sessions.
    * Use and enforce a Content Security Policy (source: Wikipedia) to
      disable any features that might be manipulated for an XSS attack.
    * Read the documentation for any of the libraries referenced in your
      code to understand which elements allow for embedded HTML.

  affected_package: org.apache.spark:spark-core_2.10
  vulnerable_versions:
  - "< 2.2.0"
  severity: medium
  package_manager: maven
  cve:
  - CVE-2017-7678
  cwe:
  - CWE-79
  disclosed_date: 2017-07-11
  created_date: 2017-08-31
  last_modified_date: 2017-08-31
  credit:
  - Mike Kasper
  - Nicholas Marion
  references:
  - http://www.openwall.com/lists/oss-security/2017/07/12/2
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHESPARK-31462
- id: snykio:maven:org.apache.spark:spark-core_2.10:31572
  title: Deserialization of Untrusted Data
  description: |
    [org.apache.spark:spark-core\_2.10][1] is a general cluster computing
    system for Big Data.

    Affected versions of this package are vulnerable to Deserialization of
    Untrusted Data. The launcher API performs unsafe deserialization of data
    received by its socket. This makes applications launched
    programmatically using the launcher API potentially vulnerable to
    arbitrary code execution by an attacker with access to any user account
    on the local machine.



    [1]: https://github.com/apache/spark
    \nSerialization is a process of converting an object into a sequence of
    bytes which can be persisted to a disk or database or can be sent
    through streams. The reverse process of creating object from sequence of
    bytes is called deserialization. Serialization is commonly used for
    communication (sharing objects between multiple hosts) and persistence
    (store the object state in a file or a database). It is an integral part
    of popular protocols like *Remote Method Invocation (RMI)*, *Java
    Management Extension (JMX)*, *Java Messaging System (JMS)*, *Action
    Message Format (AMF)*, *Java Server Faces (JSF) ViewState*, etc.

    *Deserialization of untrusted data* ([CWE-502][1]), is when the
    application deserializes untrusted data without sufficiently verifying
    that the resulting data will be valid, letting the attacker to control
    the state or the flow of the execution.

    Java deserialization issues have been known for years. However, interest
    in the issue intensified greatly in 2015, when classes that could be
    abused to achieve remote code execution were found in a [popular library
    (Apache Commons Collection)][2]. These classes were used in zero-days
    affecting IBM WebSphere, Oracle WebLogic and many other products.

    An attacker just needs to identify a piece of software that has both a
    vulnerable class on its path, and performs deserialization on untrusted
    data. Then all they need to do is send the payload into the
    deserializer, getting the command executed.

    > Developers put too much trust in Java Object Serialization. Some even
    > de-serialize objects pre-authentication. When deserializing an Object
    > in Java you typically cast it to an expected type, and therefore
    > Java\'s strict type system will ensure you only get valid object
    > trees. Unfortunately, by the time the type checking happens, platform
    > code has already created and executed significant logic. So, before
    > the final type is checked a lot of code is executed from the
    > readObject() methods of various objects, all of which is out of the
    > developer\'s control. By combining the readObject() methods of various
    > classes which are available on the classpath of the vulnerable
    > application an attacker can execute functions (including calling
    > Runtime.exec() to execute local OS commands).

    * Apache Blog

    The vulnerability, also know as *Mad Gadget*

    > Mad Gadget is one of the most pernicious vulnerabilities we’ve seen.
    > By merely existing on the Java classpath, seven “gadget” classes in
    > Apache Commons Collections (versions 3.0, 3.1, 3.2, 3.2.1, and 4.0)
    > make object deserialization for the entire JVM process Turing complete
    > with an exec function. Since many business applications use object
    > deserialization to send messages across the network, it would be like
    > hiring a bank teller who was trained to hand over all the money in the
    > vault if asked to do so politely, and then entrusting that teller with
    > the key. The only thing that would keep a bank safe in such a
    > circumstance is that most people wouldn’t consider asking such a
    > question.

    * Google



    [1]: https://cwe.mitre.org/data/definitions/502.html
    [2]: https://snyk.io/vuln/SNYK-JAVA-COMMONSCOLLECTIONS-30078
  affected_package: org.apache.spark:spark-core_2.10
  vulnerable_versions:
  - ">= 1.6.0 < 2.1.2"
  severity: high
  package_manager: maven
  cve:
  - CVE-2017-12612
  cwe:
  - CWE-502
  disclosed_date: 2017-09-13
  created_date: 2018-07-19
  last_modified_date: 2018-07-19
  credit:
  - Aditya Sharad
  references:
  - https://github.com/apache/spark/pull/18166
  - https://github.com/apache/spark/pull/18178
  - https://issues.apache.org/jira/browse/SPARK-20922
  - https://spark.apache.org/security.html#CVE-2017-12612
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHESPARK-31572
- id: snykio:maven:org.apache.spark:spark-core_2.10:31694
  title: Privilege Escalation
  description: |
    [org.apache.spark:spark-core\_2.10][1] is a cluster computing system for
    Big Data.

    Affected versions of this package are vulnerable to Privilege
    Escalation. When using `PySpark` or `SparkR`, it was possible for a
    different local user to connect to the Spark application and impersonate
    the user running the Spark application.



    [1]: https://github.com/apache/spark
  affected_package: org.apache.spark:spark-core_2.10
  vulnerable_versions:
  - "< 2.1.3"
  - ">= 2.2.0 < 2.2.2"
  severity: medium
  package_manager: maven
  cve:
  - CVE-2018-1334
  cwe:
  - CWE-265
  disclosed_date: 2018-07-11
  created_date: 2018-07-19
  last_modified_date: 2018-07-19
  credit:
  - Nehmé Tohmé
  references:
  - https://lists.apache.org/thread.html/4d6d210e319a501b740293daaeeeadb51927111fb8261a3e4cd60060@%3Cdev.spark.apache.org%3E
  - https://spark.apache.org/security.html#CVE-2018-1334
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHESPARK-31694
- id: snykio:maven:org.apache.spark:spark-core_2.10:574944
  title: Information Exposure
  description: |
    [org.apache.spark:spark-core\_2.10][1] is a cluster computing system for
    Big Data.

    Affected versions of this package are vulnerable to Information
    Exposure. In certain situations Spark would write user data to local
    disk unencrypted, even if `spark.io.encryption.enabled=true`. This
    includes cached blocks that are fetched to disk (controlled by
    `spark.maxRemoteBlockSizeFetchToMem`); in SparkR, using parallelize; in
    Pyspark, using broadcast and parallelize; and use of python udfs.



    [1]: https://github.com/apache/spark
  affected_package: org.apache.spark:spark-core_2.10
  vulnerable_versions:
  - ">= 0"
  severity: medium
  package_manager: maven
  cve:
  - CVE-2019-10099
  cwe:
  - CWE-200
  disclosed_date: 2019-08-07
  created_date: 2019-08-08
  last_modified_date: 2019-08-08
  credit:
  - Thomas Graves
  references:
  - https://github.com/apache/spark/commit/09dd34cb1706f2477a89174d6a1a0f17ed5b0a65
  - https://github.com/apache/spark/commit/575fea120e25249716e3f680396580c5f9e26b5b
  - https://github.com/apache/spark/commit/6d742d1bd71aa3803dce91a830b37284cb18cf70
  - https://issues.apache.org/jira/browse/SPARK-28626
  - https://lists.apache.org/thread.html/c2a39c207421797f82823a8aff488dcd332d9544038307bf69a2ba9e@%3Cuser.spark.apache.org%3E
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHESPARK-574944
- id: snykio:maven:org.apache.spark:spark-core_2.10:72493
  title: Information Exposure
  description: |
    [org.apache.spark:spark-core\_2.10][1] is a cluster computing system for
    Big Data.

    Affected versions of this package are vulnerable to Information
    Exposure. A specially-crafted request to the `zinc` server could cause
    it to reveal information in files readable to the developer account
    running the build.

    **Note** This vulnerability only affects developers building Spark from
    source code, and does not affect Spark end users.



    [1]: https://github.com/apache/spark
  affected_package: org.apache.spark:spark-core_2.10
  vulnerable_versions:
  - ">= 0"
  severity: high
  package_manager: maven
  cve:
  - CVE-2018-11804
  cwe:
  - CWE-200
  disclosed_date: 2018-10-24
  created_date: 2018-10-26
  last_modified_date: 2018-10-26
  credit:
  - Andre Protas
  references:
  - https://github.com/apache/spark/commit/c21d7e1bb958a0cfa4cba34a688d594466088c9e#diff-82a8bb79badc9c6f7d7c685b82d9004a
  - https://lists.apache.org/thread.html/2b11aa4201e36f2ec8f728e722fe33758410f07784379cbefd0bda9d@%3Cdev.spark.apache.org%3E
  source_url: https://snyk.io/vuln/SNYK-JAVA-ORGAPACHESPARK-72493
